{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdwShOg6bjaXdNoM9GA06q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aysha2016/Unet/blob/main/Attention_U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hFf3_MJOBmyt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Attention U-Net extends the original U-Net architecture by incorporating attention mechanisms to enhance feature representation and focus on relevant image regions during the segmentation **process**"
      ],
      "metadata": {
        "id": "PX20jYFYFXkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(x, num_filters):\n",
        "       #convolution for the gating signal\n",
        "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = L.BatchNormalization()(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "\n",
        "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = L.BatchNormalization()(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(x, num_filters):\n",
        "    x = conv_block(x, num_filters)\n",
        "    p = L.MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def attention_gate(g, s, num_filters):\n",
        "    Wg = L.Conv2D(num_filters, 1, padding=\"same\")(g)\n",
        "    Wg = L.BatchNormalization()(Wg)\n",
        "\n",
        "    Ws = L.Conv2D(num_filters, 1, padding=\"same\")(s)\n",
        "    Ws = L.BatchNormalization()(Ws)\n",
        "\n",
        "    out = L.Activation(\"relu\")(Wg + Ws)\n",
        "    out = L.Conv2D(num_filters, 1, padding=\"same\")(out)\n",
        "    out = L.Activation(\"sigmoid\")(out)\n",
        "\n",
        "    return out * s\n",
        "\n",
        "def decoder_block(x, s, num_filters):\n",
        "    #Decoder Block\n",
        "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
        "    s = attention_gate(x, s, num_filters)\n",
        "    x = L.Concatenate()([x, s])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def attention_unet(input_shape):\n",
        "   # Attention U-Net model\n",
        "    inputs = L.Input(input_shape)\n",
        "\n",
        "    # Encoder blocks with skip connections\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "\n",
        "    # Bottleneck block\n",
        "\n",
        "    b1 = conv_block(p3, 512)\n",
        "\n",
        "    # Decoder blocks with attention gates\n",
        "    d1 = decoder_block(b1, s3, 256)\n",
        "    d2 = decoder_block(d1, s2, 128)\n",
        "    d3 = decoder_block(d2, s1, 64)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n",
        "\n",
        "     # Create the Attention U-Net model\n",
        "    model = Model(inputs, outputs, name=\"Attention-UNET\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (256, 256, 3)\n",
        "    model = attention_unet(input_shape)\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9DriEh_FYaw",
        "outputId": "8780f992-f698-4f6f-c027-944868f83a23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Attention-UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 256, 256, 64  1792        ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 256, 256, 64  256        ['conv2d_24[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_20[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 256, 256, 64  36928       ['activation_20[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 256, 256, 64  256        ['conv2d_25[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 128, 128, 64  0          ['activation_21[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_3[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 128, 12  512        ['conv2d_26[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_22[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 128, 128, 12  147584      ['activation_22[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 128, 128, 12  512        ['conv2d_27[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_23[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 512)  0          ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 64, 64, 256)  131328      ['up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 64, 64, 256)  65792       ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 64, 64, 256)  0          ['batch_normalization_28[0][0]', \n",
            " mbda)                                                            'batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 64, 64, 256)  0           ['tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 64, 64, 256)  65792       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 64, 64, 256)  0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, 64, 64, 256)  0          ['activation_29[0][0]',          \n",
            " )                                                                'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 64, 768)  0           ['up_sampling2d_3[0][0]',        \n",
            "                                                                  'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 25  0          ['activation_31[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 128, 128, 12  32896       ['up_sampling2d_4[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 128, 128, 12  16512       ['activation_23[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128, 128, 12  512        ['conv2d_37[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 128, 128, 12  512        ['conv2d_38[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 128, 128, 12  0          ['batch_normalization_32[0][0]', \n",
            " mbda)                          8)                                'batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 128, 128, 12  0           ['tf.__operators__.add_4[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 128, 128, 12  16512       ['activation_32[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 128, 128, 12  0           ['conv2d_39[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  (None, 128, 128, 12  0          ['activation_33[0][0]',          \n",
            " )                              8)                                'activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_4[0][0]',        \n",
            "                                4)                                'tf.math.multiply_4[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_4[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 128, 128, 12  512        ['conv2d_40[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_34[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 128, 128, 12  147584      ['activation_34[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 128, 128, 12  512        ['conv2d_41[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_35[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 12  0          ['activation_35[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 256, 256, 64  8256        ['up_sampling2d_5[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 256, 256, 64  4160        ['activation_21[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 256, 256, 64  256        ['conv2d_42[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 256, 256, 64  256        ['conv2d_43[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 256, 256, 64  0          ['batch_normalization_36[0][0]', \n",
            " mbda)                          )                                 'batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 256, 256, 64  0           ['tf.__operators__.add_5[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 256, 256, 64  4160        ['activation_36[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 256, 256, 64  0           ['conv2d_44[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (None, 256, 256, 64  0          ['activation_37[0][0]',          \n",
            " )                              )                                 'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_5[0][0]',        \n",
            "                                2)                                'tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_5[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 256, 256, 64  256        ['conv2d_45[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 256, 256, 64  36928       ['activation_38[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 256, 256, 64  256        ['conv2d_46[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 256, 256, 1)  65          ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,143,169\n",
            "Trainable params: 8,135,745\n",
            "Non-trainable params: 7,424\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}